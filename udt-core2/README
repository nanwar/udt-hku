Decision Tree Classification With Uncertain Data (UDT) Version 0.85

Copyright (C) 2009, The Database Group, 
Department of Computer Science, The University of Hong Kong

==== Introduction of the software ====

This software is developed by Smith Tsang for the following paper:

Smith Tsang, Ben Kao, Kevin Y. Yip, Wai-Shing Ho, and Sau Dan Lee. 
Decision trees for uncertain data. In Proceedings of the 25th International 
Conference on Data Engineering (ICDE 2009), pages 441-444, Shanghai, China, 
29th March-2nd April 2009.  

And in Bibtex.

   @inproceedings{DBLP:conf/icde/TsangKYHL09,
     author    = {Smith Tsang and
                  Ben Kao and
                  Kevin Y. Yip and
                  Wai-Shing Ho and
                  Sau Dan Lee},
     title     = {Decision Trees for Uncertain Data},
     booktitle = {ICDE},
     year      = {2009},
     pages     = {441-444},
     ee        = {http://dx.doi.org/10.1109/ICDE.2009.26},
     crossref  = {DBLP:conf/icde/2009},
     bibsource = {DBLP, http://dblp.uni-trier.de}
   }

   @proceedings{DBLP:conf/icde/2009,
     title     = {Proceedings of the 25th International Conference on Data
                  Engineering, ICDE 2009, March 29th - April 2nd, Shanghai,
                  China},
     booktitle = {ICDE},
     publisher = {IEEE},
     year      = {2009},
     isbn      = {978-0-7695-3545-6},
     bibsource = {DBLP, http://dblp.uni-trier.de}
   }


For enquires on the software, you can contact through email to Smith Tsang by 	
pktsang@cs.hku.hk or smithtsang@gmail.com.


==== System Requirements ====
The software is recommended to run on a system of the following requirements
- Intel Pentinum 4 PC or above
- 2GB or above of main memory
- Linux System, e.g. Ubuntu Linux 8.04.
- Sun JavaSE JDK 6.0
If you are experienced out of memory error during execution for Java VM, you may increase 
the heap size of the Java VM using -Xms and -Xmx VM arguments. (e.g. java -Xms512m -Xmx1024m <program>)
For details, please refer to Sun JavaSE documentations.

==== Installing the Software ====
To install the software is simple. After you download the software (e.g., UDT_0.9.tar.gz),
extract it by using a unpacking software or by the following command in a linux terminal
(make sure in the terminal, you are in the directory of your software, e.g. the home directory ~/)

tar -xzvf UDT_0.9.tar.gz <directory> 

You may unpack the software in any directory you want, e.g. in '~/UDT_0.9'. 
There would be a pre-compiled jar file available for you in the directory. 
Or you can compile your own jar file by the source code:

mkdir <directory>
javac -classpath lib/log4j-1.2.15.jar  src/com/decisiontree/**/*.java  -d <directory>
jar cvf udt_0.85.jar -C <directory> .
rm -r <directory>

You can compile your code in any temporary directory, the preferred on would be 
'class' folder under the directory of your software.

After the compilation, the compiled class would be packed as a jar file 'udt_0.85.jar' under
the directory of your software. You are now ready to execute the software.

==== Executing the Software ====
The software currently consists of a command-line version.
The program can be executed in a terminal by the following commands if your program 
jar file is named as udt_0.85.jar:

java -classpath lib/log4j-1.2.15.jar:udt_0.85.jar com.decisiontree.app.UDTApp

The followings are the commands of the software:

 -mode <value>  	The decision tree building mode. The available mode include:
					gen		- 	Generate uncertain data.
					build   - 	Build decision tree.
					clean   - 	Clean generated uncertain data 
								(The operation cannot be roll-backed!)
					overall - 	Generate uncertain data and build the decision tree. 
                           	  	This mode allow result to be save in files.
                           	  
 -m <value>			Same as -mode.            
 
 -dataset <value>	Specify the dataset. The command must be use for the software to run.
 					Noted that you need NOT to specify the file extension.
 
 -d <value>			Same as -dataset.

 -test <value>		Specify the testing set.
 
 -t <value>			Same as -test
 
 -sample <value>	Specify number of sample 	(for generate/build/clean interval-valued 
 												 sample-distributed data ONLY)		

 -s <value>			Same as -sample
 
 -algorithm <value>	The algorithm to be used for finding the best split.
 						
 						The followings are for interval-valued sample-distributed data.
 						UDT 	- 	No Pruning Mode for Sampled interval data.
 						UDTBP	-	Basic Pruning Mode for Sampled interval data.
 						UDTLP	-	Local Pruning Mode for Sampled interval data.
 						UDTGP	-	Global Pruning Mode for Sampled interval data.
 						UDTES	-	End-point Sampling Mode for Sampled interval data.
 						AVG		-	Averaging Mode for Sampled interval data.
 						
 						The followings are for interval-valued data and point data.
 						UDTUD	-	Basic Pruning for interval-valued data
 						AVGUD	-	Averaging Mode for interval-valued data.
 						POINT	-	POINT data decision tree. (Not exactly C4.5)
 						
 -a <value>			Same as -algorithm.
 

The commands for build and overall mode.

 -type <value>		The build type of the software
 					xfold 			- 	Doing cross-fold validation for dataset and return the accuracy
 					accuracy 		- 	Build the decision tree using the dataset 
 										and get the accuracy using the training set.
 					time (or build) - 	Build the decision tree, record the building time informations 
 										and number of entropy calculations.  
 										(Printing and store the decision tree is currently NOT available.)
 
 -t <value>			Same as -type
 										
 -nodesize <value>	The pruning node size of pre-pruning. The decision tree building would stop if 
 					the node size is smaller than or equal to the given value.

 -n <value>			Same as -nodesize.

 -purity <value>	The pruning purity of the node of pre-pruning. The decision tree building would stop if
 					the node purity is higher than or equal to the given value.

 -p <value>			Same as -purity.

The commands for gen and overall mode.	

 -width <value>		The width of the generated interval, relative to the domain size of each attribute.
 
 -w <value>			Same as -width. 	
					
 -seed <value>		The seed value to generate the Gaussian samples for the intervals. 
 
 -e <value>			Same as -seed.

The commands for overall mode ONLY.

 -trial <value>		The number of trials of tree building to be run at the same time. 
 					Different trials would use different seed to generate the samples (if needed).
 					
 -t <value>			Same as -trial.
 
 -save <value>		Saving the result in a file given.

==== Pre-structured Datasets ====
There 10 pre-structured datasets: (Please refer to the ICDE paper for more details).

JapaneseVowel is an "uncertain data" which includes pre-structured sampled data. 
Each attribute value is an interval, which contains 30 samples.
All other dataset are point datasets and will need use our uncertain data generator
for uncertain data classification.

PenDigits and Satellite includes testing test in form of test.data.

Note: 	The sample data transformer is currently unavailable, but will be added for future release.

Acknowledgement:
Asuncion, A. & Newman, D.J. (2007). UCI Machine Learning Repository 
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA: University of California, 
School of Information and Computer Science. 

==== File Extension for dataset ====
.name = the dataset property file
.data = the dataset file (POINT data)
.range = the dataset file (RANGE data)
.error = the dataset file (SAMPLE data). The samples are stored under <filename>_PDF/ directory.


==== File Format for dataset ====
Propery file: (.name)
The first line would be the class sepeated by comma (e.g., play, not play).
The each line from the second line would represent an attribute. The attribute name would come first 
while the attribute values would come after the colon. If the attribute is continuous, a keyword continuous
should be written after the colon. If it is a categorical attribute (NOT IMPLEMETED), the attribute
values are seperated by comma. (e.g. Temperature:continuous or Outlook:Smart,Sporty,Formal)
The number of classes and attribute are not restricted.

Dataset file:
Each line represents a tuple, each attribute is comma seperated, the last value is the class label of the tuple
(e.g., Smart,0.05,2.4,play represents the tuple having 3 attributes, with the first one is categorical, 
the second and third one are point-valued.)

Point dataset (.data) -		Each attribute value is a point-valued, representing by a real-valued number, e.g. '2.45'.

Range dataset (.range) - 	Each attribute is an interval, represented by the two
							real-valued boundaries separated by ->, e.g., '2.34->4.56'.

Sample dataset (.sample) - 	Same as .range, but sample data has the samples for each attribute value stored in the 
							folder '<dataset>_PDF/'. The sample values are stored in a file for each attribute value 
							in bytecode format. Each sample is represented by a sample value and a cumulative distribution 
							(e.g. '2.5,0.9' represent a sample valued at 2.5 having cumulative probability of 0.9). 
							Here we assume each attribute value have a weighted of 1.0, so the cumulative distribution of 
							the last sample in each file would be of weight of 1.0. The name of the sample for each attribute 
							value is 'TiAj' where i is the tuple number and j is the attribute number.

Nore: 	The sample data transformer is currently unavailable, but will be added for future release.

==== Execution Examples ====

Generating interval-valued sample-distributed data for iris dataset of relative width of 0.1 and of 100 samples: 
	-dataset datasets/iris/iris -mode gen -width 0.1 -algorithmn UDT -sample 100 -seed 20

Building interval-valued sample-distributed data for iris dataset (of 100 samples) using cross-fold validation.
	-dataset datasets/iris/iris -mode build -type xfold -algorithm UDTES -nodesize 1 -threshold 0.99

Cleaning interval-valued sample-distributed data for iris dataset using cross-fold validation
	-dataset datasets/iris/iris -mode clean -algorithm UDT

Overall mode for interval-valued sample-distributed data for vehicle dataset using accuracy running 50 times 
and store the result in file
	-dataset datasets/vehicle/vehicle -test datasets/vehicle/vehicle -mode overall -type accuracy -algorithm UDT 
	-sample 100 -nodesize 1 -threshold 0.99 -seed 500 -width 0.05 -trial 50 -save result/result.rst
	
	
Note: 	Please make sure the commands are type correctly before executing the program. 
		Otherwise, it is possible to corrupt your data and results.